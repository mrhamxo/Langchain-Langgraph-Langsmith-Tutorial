{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e25acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.messages.utils import trim_messages, count_tokens_approximately\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62faeb48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8cee754",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"openai/gpt-oss-120b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3e16bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfd7cd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(state: MessagesState):\n",
    "    \n",
    "    # Trim conversation history -> last N messages that fit within the token budget\n",
    "    messages = trim_messages(\n",
    "        state[\"messages\"],\n",
    "        strategy=\"last\",                      \n",
    "        token_counter=count_tokens_approximately,\n",
    "        max_tokens=MAX_TOKENS\n",
    "    )\n",
    "\n",
    "    print('Current Token Count ->', count_tokens_approximately(messages=messages))\n",
    "\n",
    "    for message in messages:\n",
    "        print(message.content)\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d24268c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x241f66133b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d39e0806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x00000241F66108C0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = InMemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78aa7aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Token Count -> 10\n",
      "Hi, my name is Hamza.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello Hamza! Nice to meet you. How can I assist you today?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"chat-1\"}}\n",
    "\n",
    "result = graph.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Hi, my name is Hamza.\"}]},\n",
    "    config,\n",
    ")\n",
    "\n",
    "result[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb864ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Token Count -> 40\n",
      "Hi, my name is Hamza.\n",
      "Hello Hamza! Nice to meet you. How can I assist you today?\n",
      "I am learning LangGraph.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Great! LangGraph is a powerful framework for building composable, multiâ€‘step LLM applications (agents, workflows, toolâ€‘calling pipelines, etc.). Hereâ€™s a quick roadmap to get you up to speed, plus some resources and tips you can dive into right away.\\n\\n---\\n\\n## 1ï¸âƒ£ Core Concepts at a Glance\\n\\n| Concept | What It Is | Why It Matters |\\n|---------|------------|----------------|\\n| **Node** | A single â€œstepâ€ in a graphâ€”usually a call to an LLM, a tool, or some custom Python function. | Encapsulates a piece of logic that can be reused. |\\n| **Edge** | The directed connection between nodes, often conditional (e.g., based on the LLMâ€™s output). | Determines the flow of control and data. |\\n| **State** | A mutable dictionary (`state`) that travels with the execution, holding inputs, intermediate results, and metadata. | Lets downstream nodes read/write information without global variables. |\\n| **Graph** | The full DAG (or more general graph) that ties nodes and edges together. | Represents the overall workflow/agent. |\\n| **Runner** | The engine that executes the graph (`graph.compile()`, `graph.stream()`, `graph.invoke()`). | Handles async execution, streaming, retries, etc. |\\n| **Checkpointing** | Persisting the state after each step (often to a DB or file). | Enables resumable runs, debugging, and observability. |\\n\\n---\\n\\n## 2ï¸âƒ£ Minimal â€œHelloâ€‘Worldâ€ Example\\n\\n```python\\nfrom langgraph.graph import StateGraph\\nfrom langgraph.checkpoint import MemoryCheckpoint\\nfrom langchain_openai import ChatOpenAI\\n\\n# 1ï¸âƒ£ Define the LLM weâ€™ll use\\nllm = ChatOpenAI(model=\"gpt-4o-mini\")\\n\\n# 2ï¸âƒ£ Create a graph object\\ngraph = StateGraph(checkpoint=MemoryCheckpoint())\\n\\n# 3ï¸âƒ£ Define a node that asks the model a question\\ndef ask_question(state):\\n    prompt = \"What is the capital of France?\"\\n    response = llm.invoke(prompt)\\n    # Store the answer in the shared state\\n    return {\"answer\": response.content}\\n\\ngraph.add_node(\"ask\", ask_question)\\n\\n# 4ï¸âƒ£ Define a terminal node that just returns the result\\ndef end(state):\\n    return state  # nothing to change\\n\\ngraph.add_node(\"end\", end)\\n\\n# 5ï¸âƒ£ Wire the edges\\ngraph.set_entry_point(\"ask\")\\ngraph.add_edge(\"ask\", \"end\")   # after asking, go to end\\n\\n# 6ï¸âƒ£ Compile and run\\napp = graph.compile()\\nresult = app.invoke({})\\nprint(\"ðŸ—ºï¸  Final state:\", result)\\n```\\n\\n**What you see:**\\n- A **state** dictionary (`{}`) is passed in, enriched by each node, and finally returned.\\n- The graph is *acyclic* (DAG) here, but LangGraph also supports loops and conditional branches.\\n\\n---\\n\\n## 3ï¸âƒ£ Building Something More Realistic\\n\\n### a) Conditional Branching\\n\\n```python\\ndef decide(state):\\n    # Suppose the LLM returned a sentiment score in `state[\"sentiment\"]`\\n    if state[\"sentiment\"] > 0.7:\\n        return \"positive_path\"\\n    else:\\n        return \"negative_path\"\\n\\ngraph.add_node(\"decide\", decide)\\ngraph.add_conditional_edges(\\n    source=\"decide\",\\n    condition_map={\\n        \"positive_path\": \"positive_handler\",\\n        \"negative_path\": \"negative_handler\",\\n    },\\n)\\n```\\n\\n### b) Loops (e.g., Reâ€‘asking until a confidence threshold)\\n\\n```python\\ndef check_confidence(state):\\n    if state.get(\"confidence\", 0) < 0.9:\\n        return \"reask\"\\n    return \"done\"\\n\\ngraph.add_node(\"check_confidence\", check_confidence)\\ngraph.add_conditional_edges(\\n    source=\"check_confidence\",\\n    condition_map={\"reask\": \"ask\", \"done\": \"end\"},\\n)\\n```\\n\\n### c) Tool Integration\\n\\n```python\\ndef search_web(state):\\n    query = state[\"question\"]\\n    # Imagine you have a `search` function that hits an external API\\n    results = search(query)  \\n    return {\"search_results\": results}\\n\\ngraph.add_node(\"search\", search_web)\\ngraph.add_edge(\"ask\", \"search\")\\ngraph.add_edge(\"search\", \"decide\")\\n```\\n\\n---\\n\\n## 4ï¸âƒ£ Persistence & Observability\\n\\n| Need | Builtâ€‘in Option | Quick Example |\\n|------|----------------|---------------|\\n| **Checkpointing** | `MemoryCheckpoint`, `SQLiteCheckpoint`, `RedisCheckpoint`, custom DB | `graph = StateGraph(checkpoint=SQLiteCheckpoint(\"run.db\"))` |\\n| **Logging** | Use Pythonâ€™s `logging` or plug in LangGraphâ€™s callbacks | ```python\\\\nfrom langgraph.callbacks import StdOutCallbackHandler\\\\nhandler = StdOutCallbackHandler()\\\\napp = graph.compile(callbacks=[handler])\\\\n``` |\\n| **Tracing** | OpenTelemetry integration (via `langgraph.tracing`) | ```python\\\\nfrom langgraph.tracing import OpenTelemetryTracer\\\\ntracer = OpenTelemetryTracer()\\\\napp = graph.compile(callbacks=[tracer])\\\\n``` |\\n\\nThese tools let you pause/resume a run, replay a failed step, or visualize the execution DAG in tools like **LangSmith**.\\n\\n---\\n\\n## 5ï¸âƒ£ Recommended Learning Path\\n\\n| Step | Resource | What Youâ€™ll Get |\\n|------|----------|-----------------|\\n| **1ï¸âƒ£ Intro** | LangGraph docs â€“ *Getting Started* section | Minimal runnable example, API surface overview. |\\n| **2ï¸âƒ£ Core Patterns** | Blog post â€œDesigning LLM Agents with LangGraphâ€ (by LangChain team) | Patterns for loops, branching, tool usage. |\\n| **3ï¸âƒ£ Realâ€‘World Project** | **LangGraphâ€‘Chatbot** repo on GitHub (search â€œlanggraphâ€‘chatbotâ€) | Endâ€‘toâ€‘end chatbot with memory, tool calling, and UI. |\\n| **4ï¸âƒ£ Advanced** | LangGraph **Tutorial Notebook** (Colab) â€“ *Multiâ€‘Agent orchestration* | Multiâ€‘graph composition, dynamic node creation. |\\n| **5ï¸âƒ£ Production** | LangSmith + LangGraph integration guide | Monitoring, versioning, and A/B testing of graph runs. |\\n| **6ï¸âƒ£ Community** | Join the **#langgraph** channel on the LangChain Discord | Ask questions, see how others structure graphs. |\\n\\n---\\n\\n## 6ï¸âƒ£ Common Pitfalls & How to Avoid Them\\n\\n| Pitfall | Symptom | Fix |\\n|---------|---------|-----|\\n| **Unbounded loops** | Execution never finishes, or hits recursion limit. | Always include a termination condition (`max_iterations`, confidence threshold, timeout). |\\n| **State bloat** | `state` grows huge â†’ slower serialization, checkpoint size explosion. | Store only essential data; offload large blobs (e.g., PDFs) to external storage and keep a reference ID. |\\n| **Mismatched edge names** | `add_edge(\"a\", \"b\")` but node `\"b\"` isnâ€™t defined â†’ runtime error. | Run a quick sanity check: `graph.validate()` before compiling. |\\n| **Blocking I/O in nodes** | Node does a longâ€‘running HTTP call â†’ whole graph stalls. | Make the node **async** (`async def`) and use `await` for I/O; LangGraph runners handle async natively. |\\n| **Missing checkpoint** | Crash midâ€‘run loses all progress. | For any nonâ€‘trivial workflow, use a persistent checkpoint (SQLite, Redis, etc.). |\\n\\n---\\n\\n## 7ï¸âƒ£ Quick â€œNextâ€‘Stepâ€ Exercise\\n\\n**Goal:** Build a simple â€œmovie recommendationâ€ agent that:\\n\\n1. Takes a userâ€™s favorite genre (via LLM prompt).  \\n2. Calls a mock `search_movies(genre)` function.  \\n3. Returns the top 3 titles.  \\n4. If the user says â€œmoreâ€, loops back to step 2 with a new genre.\\n\\n**Skeleton:**\\n\\n```python\\nfrom langgraph.graph import StateGraph\\nfrom langchain_openai import ChatOpenAI\\n\\nllm = ChatOpenAI(model=\"gpt-4o-mini\")\\n\\ndef get_genre(state):\\n    prompt = \"Ask the user for their favorite movie genre.\"\\n    resp = llm.invoke(prompt)\\n    return {\"genre\": resp.content.strip()}\\n\\ndef search_movies(state):\\n    genre = state[\"genre\"]\\n    # Mock data â€“ replace with a real API later\\n    catalog = {\\n        \"action\": [\"Die Hard\", \"Mad Max: Fury Road\", \"John Wick\"],\\n        \"comedy\": [\"Superbad\", \"Step Brothers\", \"The Grand Budapest Hotel\"],\\n        # â€¦\\n    }\\n    results = catalog.get(genre.lower(), [\"No movies found\"])\\n    return {\"movies\": results[:3]}\\n\\ndef ask_more(state):\\n    prompt = \"Would you like more recommendations? (yes/no)\"\\n    resp = llm.invoke(prompt)\\n    return {\"more\": resp.content.lower().startswith(\"y\")}\\n\\n# Build graph\\ngraph = StateGraph()\\ngraph.add_node(\"genre\", get_genre)\\ngraph.add_node(\"search\", search_movies)\\ngraph.add_node(\"more\", ask_more)\\ngraph.add_node(\"end\", lambda s: s)\\n\\ngraph.set_entry_point(\"genre\")\\ngraph.add_edge(\"genre\", \"search\")\\ngraph.add_edge(\"search\", \"more\")\\ngraph.add_conditional_edges(\\n    source=\"more\",\\n    condition_map={True: \"search\", False: \"end\"},\\n)\\n\\napp = graph.compile()\\nprint(app.invoke({}))\\n```\\n\\nRun it, tweak the prompts, and then replace `search_movies` with a real TMDB or OMDB API call. Thatâ€™ll give you handsâ€‘on experience with **state passing**, **conditional loops**, and **tool integration**.\\n\\n---\\n\\n## 8ï¸âƒ£ Where to Go From Here\\n\\n- **Experiment**: Clone a few openâ€‘source LangGraph repos and modify a node or two.  \\n- **Add a UI**: Hook the compiled graph to a FastAPI endpoint or a Streamlit appâ€”LangGraph works seamlessly with async frameworks.  \\n- **Scale**: When youâ€™re ready for production, look into **LangGraphâ€™s distributed execution** (via Ray or Dask) and **parallel branches** for multiâ€‘agent setups.  \\n\\n---\\n\\nIf you have a specific useâ€‘case, a piece of code thatâ€™s giving you trouble, or just want deeper explanations of any of the concepts above, let me know! Iâ€™m happy to dive into details or walk through a concrete example with you. ðŸš€'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = graph.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"I am learning LangGraph.\"}]},\n",
    "    config,\n",
    ")\n",
    "\n",
    "result[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f0d55c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Token Count -> 13\n",
      "Can you explain short term memory?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'### Shortâ€‘Term Memory (STM) â€“ A Quick Overview\\n\\n**Shortâ€‘term memory** is the brainâ€™s â€œmental notepadâ€ that holds a small amount of information for a brief periodâ€”typically seconds to a few minutesâ€”while weâ€™re actively using it. Itâ€™s essential for everyday tasks like remembering a phone number long enough to dial it, keeping track of the items on a shopping list while you walk through the store, or following a conversation.\\n\\nBelow is a concise guide covering the key features, underlying mechanisms, and how STM fits into the broader memory system.\\n\\n---\\n\\n## 1. Core Characteristics\\n\\n| Feature | Typical Value | What It Means |\\n|---------|---------------|---------------|\\n| **Capacity** | 4â€“9 â€œchunksâ€ of information (Millerâ€™s classic 7\\u202fÂ±\\u202f2) | A *chunk* can be a single digit, a word, or a meaningful group (e.g., â€œNew\\u202fYorkâ€ counts as one chunk). |\\n| **Duration** | ~15â€“30\\u202fseconds without rehearsal | If you donâ€™t actively repeat or rehearse the info, it fades quickly. |\\n| **Encoding** | Primarily **acoustic** (sound) and **visual** (spatial) | You often â€œhearâ€ the items in your mind (e.g., silently repeating a phone number). |\\n| **Retrieval** | Immediate, but fragile | You can pull it out right away, but itâ€™s vulnerable to interference (e.g., hearing a new number can overwrite the old one). |\\n\\n---\\n\\n## 2. How STM Works in the Brain\\n\\n| Brain Region | Role in STM | Notable Findings |\\n|--------------|------------|------------------|\\n| **Prefrontal Cortex (PFC)** | Executive control, manipulation of items (working memory) | Damage to the PFC impairs the ability to hold and reorganize information. |\\n| **Parietal Cortex** | Spatial and attentional aspects | Involved when you keep a mental map of where objects are. |\\n| **Temporal Lobe (especially the auditory cortex)** | Acoustic encoding | Supports the â€œinner voiceâ€ rehearsal loop. |\\n| **Hippocampus** | Not essential for STM itself, but crucial for transferring info to longâ€‘term memory (LTM) | STM can operate without the hippocampus, but consolidation into LTM usually needs it. |\\n\\n---\\n\\n## 3. STM vs. Working Memory\\n\\n- **Shortâ€‘Term Memory**: Often used to describe the *storage* componentâ€”holding raw items for a few seconds.\\n- **Working Memory**: A broader construct that includes *both* storage and *manipulation* of information (e.g., solving a mental math problem). Baddeleyâ€™s model splits working memory into:\\n  1. **Phonological Loop** â€“ auditory/verbal rehearsal.\\n  2. **Visuospatial Sketchpad** â€“ visual and spatial imagery.\\n  3. **Central Executive** â€“ attentional control.\\n  4. **Episodic Buffer** (added later) â€“ integrates information across modalities and links to LTM.\\n\\nIn everyday language, â€œshortâ€‘term memoryâ€ and â€œworking memoryâ€ are sometimes used interchangeably, but the distinction matters in research and clinical settings.\\n\\n---\\n\\n## 4. Why STM Is Limited\\n\\n1. **Neural Resource Constraints** â€“ Maintaining active firing patterns for many items consumes metabolic energy.\\n2. **Interference** â€“ New incoming information can overwrite or disrupt existing traces (especially when theyâ€™re similar).\\n3. **Decay** â€“ Without rehearsal, the neural representation weakens over time.\\n\\n---\\n\\n## 5. Strategies to Boost STM Performance\\n\\n| Technique | How It Helps |\\n|-----------|--------------|\\n| **Chunking** | Groups items into larger, meaningful units (e.g., â€œ1776â€ instead of â€œ1â€‘7â€‘7â€‘6â€). |\\n| **Rehearsal (Repeating Out Loud or Silently)** | Keeps the neural trace active, extending duration. |\\n| **Mnemonic Devices** | Links new info to familiar patterns (e.g., acronyms, visual images). |\\n| **Reducing Distractions** | Lessens interference from competing stimuli. |\\n| **Dualâ€‘coding** | Pairing verbal info with visual imagery can create two retrieval pathways. |\\n\\n---\\n\\n## 6. Realâ€‘World Examples\\n\\n| Situation | STM in Action |\\n|-----------|---------------|\\n| **Dialing a Phone Number** | You repeat the digits in your head (phonological loop) until you finish dialing. |\\n| **Following Directions** | You keep the next turn (â€œright at the next intersectionâ€) in mind while walking. |\\n| **Reading a Sentence** | You hold the words youâ€™ve just read while integrating them into the overall meaning. |\\n| **Mental Math** | You store intermediate results (e.g., â€œ12\\u202fÃ—\\u202f8\\u202f=\\u202f96â€) while you continue the calculation. |\\n\\n---\\n\\n## 7. STM in Development and Aging\\n\\n- **Children**: STM capacity increases with age, reaching adult levels around 7â€“8\\u202fyears old.\\n- **Older Adults**: May experience a slight decline in capacity and speed of rehearsal, but strategies like chunking can mitigate the effect.\\n- **Clinical Conditions**:  \\n  - **ADHD**: Often shows reduced STM capacity and increased distractibility.  \\n  - **Alzheimerâ€™s Disease**: Early deficits are usually in the transfer from STM to LTM rather than STM storage itself.  \\n  - **Aphasia** (postâ€‘stroke language disorder): Can impair the phonological loop, making verbal STM difficult.\\n\\n---\\n\\n## 8. Quick Summary Checklist\\n\\n- **Capacity**: ~4â€“9 chunks.  \\n- **Duration**: ~15â€“30\\u202fseconds without rehearsal.  \\n- **Encoding**: Primarily acoustic & visual.  \\n- **Brain Areas**: Prefrontal & parietal cortices, auditory/visual cortices.  \\n- **Boosters**: Chunking, rehearsal, mnemonics, minimizing distractions.  \\n\\n---\\n\\n### TL;DR\\n\\nShortâ€‘term memory is a limitedâ€‘capacity, shortâ€‘lived storage system that lets us keep a few pieces of information â€œonlineâ€ for seconds to minutes. It relies on active neural firing in frontal and parietal regions, is vulnerable to decay and interference, and can be strengthened with simple strategies like chunking and rehearsal. It forms the foundation for working memory, which adds the ability to manipulate those stored items for tasks such as mental calculation or problem solving.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = graph.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Can you explain short term memory?\"}]},\n",
    "    config,\n",
    ")\n",
    "\n",
    "result[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab6325e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Token Count -> 8\n",
      "What is my name?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I donâ€™t actually know your nameâ€”could you let me know what youâ€™d like me to call you?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = graph.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is my name?\"}]},\n",
    "    config,\n",
    ")\n",
    "\n",
    "result[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "223ca649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, my name is Hamza.\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Hello Hamza! Nice to meet you. How can I assist you today?\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "I am learning LangGraph.\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Great! LangGraph is a powerful framework for building composable, multiâ€‘step LLM applications (agents, workflows, toolâ€‘calling pipelines, etc.). Hereâ€™s a quick roadmap to get you up to speed, plus some resources and tips you can dive into right away.\n",
      "\n",
      "---\n",
      "\n",
      "## 1ï¸âƒ£ Core Concepts at a Glance\n",
      "\n",
      "| Concept | What It Is | Why It Matters |\n",
      "|---------|------------|----------------|\n",
      "| **Node** | A single â€œstepâ€ in a graphâ€”usually a call to an LLM, a tool, or some custom Python function. | Encapsulates a piece of logic that can be reused. |\n",
      "| **Edge** | The directed connection between nodes, often conditional (e.g., based on the LLMâ€™s output). | Determines the flow of control and data. |\n",
      "| **State** | A mutable dictionary (`state`) that travels with the execution, holding inputs, intermediate results, and metadata. | Lets downstream nodes read/write information without global variables. |\n",
      "| **Graph** | The full DAG (or more general graph) that ties nodes and edges together. | Represents the overall workflow/agent. |\n",
      "| **Runner** | The engine that executes the graph (`graph.compile()`, `graph.stream()`, `graph.invoke()`). | Handles async execution, streaming, retries, etc. |\n",
      "| **Checkpointing** | Persisting the state after each step (often to a DB or file). | Enables resumable runs, debugging, and observability. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2ï¸âƒ£ Minimal â€œHelloâ€‘Worldâ€ Example\n",
      "\n",
      "```python\n",
      "from langgraph.graph import StateGraph\n",
      "from langgraph.checkpoint import MemoryCheckpoint\n",
      "from langchain_openai import ChatOpenAI\n",
      "\n",
      "# 1ï¸âƒ£ Define the LLM weâ€™ll use\n",
      "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
      "\n",
      "# 2ï¸âƒ£ Create a graph object\n",
      "graph = StateGraph(checkpoint=MemoryCheckpoint())\n",
      "\n",
      "# 3ï¸âƒ£ Define a node that asks the model a question\n",
      "def ask_question(state):\n",
      "    prompt = \"What is the capital of France?\"\n",
      "    response = llm.invoke(prompt)\n",
      "    # Store the answer in the shared state\n",
      "    return {\"answer\": response.content}\n",
      "\n",
      "graph.add_node(\"ask\", ask_question)\n",
      "\n",
      "# 4ï¸âƒ£ Define a terminal node that just returns the result\n",
      "def end(state):\n",
      "    return state  # nothing to change\n",
      "\n",
      "graph.add_node(\"end\", end)\n",
      "\n",
      "# 5ï¸âƒ£ Wire the edges\n",
      "graph.set_entry_point(\"ask\")\n",
      "graph.add_edge(\"ask\", \"end\")   # after asking, go to end\n",
      "\n",
      "# 6ï¸âƒ£ Compile and run\n",
      "app = graph.compile()\n",
      "result = app.invoke({})\n",
      "print(\"ðŸ—ºï¸  Final state:\", result)\n",
      "```\n",
      "\n",
      "**What you see:**\n",
      "- A **state** dictionary (`{}`) is passed in, enriched by each node, and finally returned.\n",
      "- The graph is *acyclic* (DAG) here, but LangGraph also supports loops and conditional branches.\n",
      "\n",
      "---\n",
      "\n",
      "## 3ï¸âƒ£ Building Something More Realistic\n",
      "\n",
      "### a) Conditional Branching\n",
      "\n",
      "```python\n",
      "def decide(state):\n",
      "    # Suppose the LLM returned a sentiment score in `state[\"sentiment\"]`\n",
      "    if state[\"sentiment\"] > 0.7:\n",
      "        return \"positive_path\"\n",
      "    else:\n",
      "        return \"negative_path\"\n",
      "\n",
      "graph.add_node(\"decide\", decide)\n",
      "graph.add_conditional_edges(\n",
      "    source=\"decide\",\n",
      "    condition_map={\n",
      "        \"positive_path\": \"positive_handler\",\n",
      "        \"negative_path\": \"negative_handler\",\n",
      "    },\n",
      ")\n",
      "```\n",
      "\n",
      "### b) Loops (e.g., Reâ€‘asking until a confidence threshold)\n",
      "\n",
      "```python\n",
      "def check_confidence(state):\n",
      "    if state.get(\"confidence\", 0) < 0.9:\n",
      "        return \"reask\"\n",
      "    return \"done\"\n",
      "\n",
      "graph.add_node(\"check_confidence\", check_confidence)\n",
      "graph.add_conditional_edges(\n",
      "    source=\"check_confidence\",\n",
      "    condition_map={\"reask\": \"ask\", \"done\": \"end\"},\n",
      ")\n",
      "```\n",
      "\n",
      "### c) Tool Integration\n",
      "\n",
      "```python\n",
      "def search_web(state):\n",
      "    query = state[\"question\"]\n",
      "    # Imagine you have a `search` function that hits an external API\n",
      "    results = search(query)  \n",
      "    return {\"search_results\": results}\n",
      "\n",
      "graph.add_node(\"search\", search_web)\n",
      "graph.add_edge(\"ask\", \"search\")\n",
      "graph.add_edge(\"search\", \"decide\")\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## 4ï¸âƒ£ Persistence & Observability\n",
      "\n",
      "| Need | Builtâ€‘in Option | Quick Example |\n",
      "|------|----------------|---------------|\n",
      "| **Checkpointing** | `MemoryCheckpoint`, `SQLiteCheckpoint`, `RedisCheckpoint`, custom DB | `graph = StateGraph(checkpoint=SQLiteCheckpoint(\"run.db\"))` |\n",
      "| **Logging** | Use Pythonâ€™s `logging` or plug in LangGraphâ€™s callbacks | ```python\\nfrom langgraph.callbacks import StdOutCallbackHandler\\nhandler = StdOutCallbackHandler()\\napp = graph.compile(callbacks=[handler])\\n``` |\n",
      "| **Tracing** | OpenTelemetry integration (via `langgraph.tracing`) | ```python\\nfrom langgraph.tracing import OpenTelemetryTracer\\ntracer = OpenTelemetryTracer()\\napp = graph.compile(callbacks=[tracer])\\n``` |\n",
      "\n",
      "These tools let you pause/resume a run, replay a failed step, or visualize the execution DAG in tools like **LangSmith**.\n",
      "\n",
      "---\n",
      "\n",
      "## 5ï¸âƒ£ Recommended Learning Path\n",
      "\n",
      "| Step | Resource | What Youâ€™ll Get |\n",
      "|------|----------|-----------------|\n",
      "| **1ï¸âƒ£ Intro** | LangGraph docs â€“ *Getting Started* section | Minimal runnable example, API surface overview. |\n",
      "| **2ï¸âƒ£ Core Patterns** | Blog post â€œDesigning LLM Agents with LangGraphâ€ (by LangChain team) | Patterns for loops, branching, tool usage. |\n",
      "| **3ï¸âƒ£ Realâ€‘World Project** | **LangGraphâ€‘Chatbot** repo on GitHub (search â€œlanggraphâ€‘chatbotâ€) | Endâ€‘toâ€‘end chatbot with memory, tool calling, and UI. |\n",
      "| **4ï¸âƒ£ Advanced** | LangGraph **Tutorial Notebook** (Colab) â€“ *Multiâ€‘Agent orchestration* | Multiâ€‘graph composition, dynamic node creation. |\n",
      "| **5ï¸âƒ£ Production** | LangSmith + LangGraph integration guide | Monitoring, versioning, and A/B testing of graph runs. |\n",
      "| **6ï¸âƒ£ Community** | Join the **#langgraph** channel on the LangChain Discord | Ask questions, see how others structure graphs. |\n",
      "\n",
      "---\n",
      "\n",
      "## 6ï¸âƒ£ Common Pitfalls & How to Avoid Them\n",
      "\n",
      "| Pitfall | Symptom | Fix |\n",
      "|---------|---------|-----|\n",
      "| **Unbounded loops** | Execution never finishes, or hits recursion limit. | Always include a termination condition (`max_iterations`, confidence threshold, timeout). |\n",
      "| **State bloat** | `state` grows huge â†’ slower serialization, checkpoint size explosion. | Store only essential data; offload large blobs (e.g., PDFs) to external storage and keep a reference ID. |\n",
      "| **Mismatched edge names** | `add_edge(\"a\", \"b\")` but node `\"b\"` isnâ€™t defined â†’ runtime error. | Run a quick sanity check: `graph.validate()` before compiling. |\n",
      "| **Blocking I/O in nodes** | Node does a longâ€‘running HTTP call â†’ whole graph stalls. | Make the node **async** (`async def`) and use `await` for I/O; LangGraph runners handle async natively. |\n",
      "| **Missing checkpoint** | Crash midâ€‘run loses all progress. | For any nonâ€‘trivial workflow, use a persistent checkpoint (SQLite, Redis, etc.). |\n",
      "\n",
      "---\n",
      "\n",
      "## 7ï¸âƒ£ Quick â€œNextâ€‘Stepâ€ Exercise\n",
      "\n",
      "**Goal:** Build a simple â€œmovie recommendationâ€ agent that:\n",
      "\n",
      "1. Takes a userâ€™s favorite genre (via LLM prompt).  \n",
      "2. Calls a mock `search_movies(genre)` function.  \n",
      "3. Returns the top 3 titles.  \n",
      "4. If the user says â€œmoreâ€, loops back to step 2 with a new genre.\n",
      "\n",
      "**Skeleton:**\n",
      "\n",
      "```python\n",
      "from langgraph.graph import StateGraph\n",
      "from langchain_openai import ChatOpenAI\n",
      "\n",
      "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
      "\n",
      "def get_genre(state):\n",
      "    prompt = \"Ask the user for their favorite movie genre.\"\n",
      "    resp = llm.invoke(prompt)\n",
      "    return {\"genre\": resp.content.strip()}\n",
      "\n",
      "def search_movies(state):\n",
      "    genre = state[\"genre\"]\n",
      "    # Mock data â€“ replace with a real API later\n",
      "    catalog = {\n",
      "        \"action\": [\"Die Hard\", \"Mad Max: Fury Road\", \"John Wick\"],\n",
      "        \"comedy\": [\"Superbad\", \"Step Brothers\", \"The Grand Budapest Hotel\"],\n",
      "        # â€¦\n",
      "    }\n",
      "    results = catalog.get(genre.lower(), [\"No movies found\"])\n",
      "    return {\"movies\": results[:3]}\n",
      "\n",
      "def ask_more(state):\n",
      "    prompt = \"Would you like more recommendations? (yes/no)\"\n",
      "    resp = llm.invoke(prompt)\n",
      "    return {\"more\": resp.content.lower().startswith(\"y\")}\n",
      "\n",
      "# Build graph\n",
      "graph = StateGraph()\n",
      "graph.add_node(\"genre\", get_genre)\n",
      "graph.add_node(\"search\", search_movies)\n",
      "graph.add_node(\"more\", ask_more)\n",
      "graph.add_node(\"end\", lambda s: s)\n",
      "\n",
      "graph.set_entry_point(\"genre\")\n",
      "graph.add_edge(\"genre\", \"search\")\n",
      "graph.add_edge(\"search\", \"more\")\n",
      "graph.add_conditional_edges(\n",
      "    source=\"more\",\n",
      "    condition_map={True: \"search\", False: \"end\"},\n",
      ")\n",
      "\n",
      "app = graph.compile()\n",
      "print(app.invoke({}))\n",
      "```\n",
      "\n",
      "Run it, tweak the prompts, and then replace `search_movies` with a real TMDB or OMDB API call. Thatâ€™ll give you handsâ€‘on experience with **state passing**, **conditional loops**, and **tool integration**.\n",
      "\n",
      "---\n",
      "\n",
      "## 8ï¸âƒ£ Where to Go From Here\n",
      "\n",
      "- **Experiment**: Clone a few openâ€‘source LangGraph repos and modify a node or two.  \n",
      "- **Add a UI**: Hook the compiled graph to a FastAPI endpoint or a Streamlit appâ€”LangGraph works seamlessly with async frameworks.  \n",
      "- **Scale**: When youâ€™re ready for production, look into **LangGraphâ€™s distributed execution** (via Ray or Dask) and **parallel branches** for multiâ€‘agent setups.  \n",
      "\n",
      "---\n",
      "\n",
      "If you have a specific useâ€‘case, a piece of code thatâ€™s giving you trouble, or just want deeper explanations of any of the concepts above, let me know! Iâ€™m happy to dive into details or walk through a concrete example with you. ðŸš€\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Can you explain short term memory?\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "### Shortâ€‘Term Memory (STM) â€“ A Quick Overview\n",
      "\n",
      "**Shortâ€‘term memory** is the brainâ€™s â€œmental notepadâ€ that holds a small amount of information for a brief periodâ€”typically seconds to a few minutesâ€”while weâ€™re actively using it. Itâ€™s essential for everyday tasks like remembering a phone number long enough to dial it, keeping track of the items on a shopping list while you walk through the store, or following a conversation.\n",
      "\n",
      "Below is a concise guide covering the key features, underlying mechanisms, and how STM fits into the broader memory system.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Core Characteristics\n",
      "\n",
      "| Feature | Typical Value | What It Means |\n",
      "|---------|---------------|---------------|\n",
      "| **Capacity** | 4â€“9 â€œchunksâ€ of information (Millerâ€™s classic 7â€¯Â±â€¯2) | A *chunk* can be a single digit, a word, or a meaningful group (e.g., â€œNewâ€¯Yorkâ€ counts as one chunk). |\n",
      "| **Duration** | ~15â€“30â€¯seconds without rehearsal | If you donâ€™t actively repeat or rehearse the info, it fades quickly. |\n",
      "| **Encoding** | Primarily **acoustic** (sound) and **visual** (spatial) | You often â€œhearâ€ the items in your mind (e.g., silently repeating a phone number). |\n",
      "| **Retrieval** | Immediate, but fragile | You can pull it out right away, but itâ€™s vulnerable to interference (e.g., hearing a new number can overwrite the old one). |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. How STM Works in the Brain\n",
      "\n",
      "| Brain Region | Role in STM | Notable Findings |\n",
      "|--------------|------------|------------------|\n",
      "| **Prefrontal Cortex (PFC)** | Executive control, manipulation of items (working memory) | Damage to the PFC impairs the ability to hold and reorganize information. |\n",
      "| **Parietal Cortex** | Spatial and attentional aspects | Involved when you keep a mental map of where objects are. |\n",
      "| **Temporal Lobe (especially the auditory cortex)** | Acoustic encoding | Supports the â€œinner voiceâ€ rehearsal loop. |\n",
      "| **Hippocampus** | Not essential for STM itself, but crucial for transferring info to longâ€‘term memory (LTM) | STM can operate without the hippocampus, but consolidation into LTM usually needs it. |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. STM vs. Working Memory\n",
      "\n",
      "- **Shortâ€‘Term Memory**: Often used to describe the *storage* componentâ€”holding raw items for a few seconds.\n",
      "- **Working Memory**: A broader construct that includes *both* storage and *manipulation* of information (e.g., solving a mental math problem). Baddeleyâ€™s model splits working memory into:\n",
      "  1. **Phonological Loop** â€“ auditory/verbal rehearsal.\n",
      "  2. **Visuospatial Sketchpad** â€“ visual and spatial imagery.\n",
      "  3. **Central Executive** â€“ attentional control.\n",
      "  4. **Episodic Buffer** (added later) â€“ integrates information across modalities and links to LTM.\n",
      "\n",
      "In everyday language, â€œshortâ€‘term memoryâ€ and â€œworking memoryâ€ are sometimes used interchangeably, but the distinction matters in research and clinical settings.\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Why STM Is Limited\n",
      "\n",
      "1. **Neural Resource Constraints** â€“ Maintaining active firing patterns for many items consumes metabolic energy.\n",
      "2. **Interference** â€“ New incoming information can overwrite or disrupt existing traces (especially when theyâ€™re similar).\n",
      "3. **Decay** â€“ Without rehearsal, the neural representation weakens over time.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Strategies to Boost STM Performance\n",
      "\n",
      "| Technique | How It Helps |\n",
      "|-----------|--------------|\n",
      "| **Chunking** | Groups items into larger, meaningful units (e.g., â€œ1776â€ instead of â€œ1â€‘7â€‘7â€‘6â€). |\n",
      "| **Rehearsal (Repeating Out Loud or Silently)** | Keeps the neural trace active, extending duration. |\n",
      "| **Mnemonic Devices** | Links new info to familiar patterns (e.g., acronyms, visual images). |\n",
      "| **Reducing Distractions** | Lessens interference from competing stimuli. |\n",
      "| **Dualâ€‘coding** | Pairing verbal info with visual imagery can create two retrieval pathways. |\n",
      "\n",
      "---\n",
      "\n",
      "## 6. Realâ€‘World Examples\n",
      "\n",
      "| Situation | STM in Action |\n",
      "|-----------|---------------|\n",
      "| **Dialing a Phone Number** | You repeat the digits in your head (phonological loop) until you finish dialing. |\n",
      "| **Following Directions** | You keep the next turn (â€œright at the next intersectionâ€) in mind while walking. |\n",
      "| **Reading a Sentence** | You hold the words youâ€™ve just read while integrating them into the overall meaning. |\n",
      "| **Mental Math** | You store intermediate results (e.g., â€œ12â€¯Ã—â€¯8â€¯=â€¯96â€) while you continue the calculation. |\n",
      "\n",
      "---\n",
      "\n",
      "## 7. STM in Development and Aging\n",
      "\n",
      "- **Children**: STM capacity increases with age, reaching adult levels around 7â€“8â€¯years old.\n",
      "- **Older Adults**: May experience a slight decline in capacity and speed of rehearsal, but strategies like chunking can mitigate the effect.\n",
      "- **Clinical Conditions**:  \n",
      "  - **ADHD**: Often shows reduced STM capacity and increased distractibility.  \n",
      "  - **Alzheimerâ€™s Disease**: Early deficits are usually in the transfer from STM to LTM rather than STM storage itself.  \n",
      "  - **Aphasia** (postâ€‘stroke language disorder): Can impair the phonological loop, making verbal STM difficult.\n",
      "\n",
      "---\n",
      "\n",
      "## 8. Quick Summary Checklist\n",
      "\n",
      "- **Capacity**: ~4â€“9 chunks.  \n",
      "- **Duration**: ~15â€“30â€¯seconds without rehearsal.  \n",
      "- **Encoding**: Primarily acoustic & visual.  \n",
      "- **Brain Areas**: Prefrontal & parietal cortices, auditory/visual cortices.  \n",
      "- **Boosters**: Chunking, rehearsal, mnemonics, minimizing distractions.  \n",
      "\n",
      "---\n",
      "\n",
      "### TL;DR\n",
      "\n",
      "Shortâ€‘term memory is a limitedâ€‘capacity, shortâ€‘lived storage system that lets us keep a few pieces of information â€œonlineâ€ for seconds to minutes. It relies on active neural firing in frontal and parietal regions, is vulnerable to decay and interference, and can be strengthened with simple strategies like chunking and rehearsal. It forms the foundation for working memory, which adds the ability to manipulate those stored items for tasks such as mental calculation or problem solving.\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "What is my name?\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "I donâ€™t actually know your nameâ€”could you let me know what youâ€™d like me to call you?\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for item in graph.get_state({\"configurable\": {\"thread_id\": \"chat-1\"}}).values['messages']:\n",
    "    print(item.content)\n",
    "    print('-'*120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9aa6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
